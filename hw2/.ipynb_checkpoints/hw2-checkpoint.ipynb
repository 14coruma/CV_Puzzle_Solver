{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "distinguished-string",
   "metadata": {},
   "source": [
    "# HW2: Probability, Naive Bayes, and Linear Regression\n",
    "**Andrew Corum, Jo Youngheun**\n",
    "\n",
    "Please grade this submission. Thanks!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "indie-silver",
   "metadata": {},
   "source": [
    "## Question 1\n",
    "### Code for building and evaluating Naive Bayes models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "adopted-capability",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/amcorum/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "# For splitting data and computing confusion matrix\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# For set of english stop words\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "checked-montgomery",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(X, y, laplace=False, ignore_stop_words=False):\n",
    "    '''\n",
    "    Calculate required values for Naive Bayes classifier,\n",
    "    so we can later compute priors and liklihoods\n",
    "    \n",
    "    Parameters:\n",
    "        X (np.array): messages\n",
    "        y (np.array): message label (0 or 1)\n",
    "        laplace (bool): Whether or not to use laplace smoothing\n",
    "    Returns:\n",
    "        model (dict):\n",
    "            {\n",
    "                'prior': {label: log(Prob(label))}\n",
    "                    log-prior probabilities of each label\n",
    "                'label_word_count': {label: log(count(label))}\n",
    "                    log-count of total number of words found in messages with each label\n",
    "                'word_counts': {word: {label: count}}\n",
    "                    for each unique word, number of times it appears in messages with each label\n",
    "            }\n",
    "    '''\n",
    "    prior = {l: 0 for l in [0,1]}\n",
    "    label_word_count = {l: 0 for l in [0,1]}\n",
    "    word_counts = {}\n",
    "    # Loop through each row in the data\n",
    "    for msg, label in zip(X, y):\n",
    "        # Keep track of number of occurances of the given label\n",
    "        prior[label] += 1\n",
    "        # Also count number of total words found in the given label\n",
    "        label_word_count[label] += len(msg.split())\n",
    "        \n",
    "        # For each word in the message, total up how many times it appears in a spam or non-spam message\n",
    "        for word in msg.split():\n",
    "            # If we are ignoring stop words, then don't count a stop word...\n",
    "            if ignore_stop_words and word in stop_words:\n",
    "                label_word_count[label] -= 1\n",
    "                continue\n",
    "            # int(laplace) tells us to initialize new words with count==1 when doing laplace smoothing\n",
    "            if word not in word_counts: word_counts[word] = {l: int(laplace) for l in [0,1]}\n",
    "            word_counts[word][label] += 1\n",
    "            \n",
    "    # Divide lable counts by total number of rows, to get prior probability. Then take log\n",
    "    prior = {l: math.log(prior[l])-math.log(len(X)) for l in prior}\n",
    "    # Take log of total word counts (since we will use log in model_predict() anyways)\n",
    "    label_word_count = {l: math.log(label_word_count[l]) for l in label_word_count}\n",
    "    \n",
    "    return {'prior': prior, 'label_word_count': label_word_count, 'word_counts': word_counts}\n",
    "\n",
    "def model_predict(model, X, laplace=False, ignore_stop_words=False):\n",
    "    '''\n",
    "    Using a pre-computed model (priors, total label word counts, and word counts per lablel),\n",
    "    predict 0,1 spam labels given input messages.\n",
    "    \n",
    "    Parameters:\n",
    "        model (dict):\n",
    "            {\n",
    "                'prior': {label: log(Prob(label))}\n",
    "                    log-prior probabilities of each label\n",
    "                'label_word_count': {label: log(count(label))}\n",
    "                    log-count of total number of words for each label\n",
    "                'word_counts': {word: {label: count}}\n",
    "                    count of each label for each unique word\n",
    "            }\n",
    "        X (np.array): messages\n",
    "        laplace (bool): Whether or not to use laplace smoothing\n",
    "    Returns:\n",
    "        y_pred (list): list of label estimates\n",
    "    '''\n",
    "    y_pred = []\n",
    "    for msg in X:\n",
    "        # Start with prior probability\n",
    "        prob0, prob1 = model['prior'][0], model['prior'][1]\n",
    "        # Multiply prior by liklihood of each word given the label\n",
    "        for word in msg.split():\n",
    "            # If ignoring stop words, ignore the stop word...\n",
    "            if ignore_stop_words and word in stop_words: continue\n",
    "            # If using laplace smoothing, set word count to 1... otherwise skip the extra word\n",
    "            if word not in model['word_counts']:\n",
    "                if laplace: model['word_counts'][word] = {0: 1, 1: 1}\n",
    "                else: continue\n",
    "            word_count = model['word_counts'][word]\n",
    "            # Again, if word not found in training set and not using laplace, skip the word\n",
    "            if not laplace and (model['word_counts'][word][0] == 0 or model['word_counts'][word][1] == 0):\n",
    "                continue\n",
    "            # word_count still needs to be put into log form\n",
    "            prob_word = [math.log(word_count[i]) for i in [0,1]]\n",
    "            \n",
    "            # logP(word | label) := log(#times <word> appears in <label> messages / total #words in <label> messages)\n",
    "            prob0 += prob_word[0] - model['label_word_count'][0]\n",
    "            prob1 += prob_word[1] - model['label_word_count'][1]\n",
    "            \n",
    "            # If laplace smoothing, need to divide liklihood by number of features (ie. number of words in the input message)\n",
    "            if laplace:\n",
    "                prob0 -= math.log(len(msg.split()))\n",
    "                prob1 -= math.log(len(msg.split()))\n",
    "                \n",
    "        y_pred.append(0 if prob0 >= prob1 else 1)\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "guilty-venice",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_stats(conf):\n",
    "    '''\n",
    "    Given a confusion matrix, compute and print accuracy, precision, recall, and specificity\n",
    "    '''\n",
    "    print(\"  Accuracy: {}\\n  Precision: {}\\n  Recal: {}\\n  Specificity: {}\".format(\n",
    "        (conf[0][0]+conf[1][1])/sum(sum(conf)),\n",
    "        conf[1][1]/(conf[1][1] + conf[1][0]),\n",
    "        conf[1][1]/(conf[1][1] + conf[0][1]),\n",
    "        conf[0][0]/(conf[0][0] + conf[1][0])\n",
    "    ))\n",
    "\n",
    "def evaluate_naive_bayes(X, y, laplace=False):\n",
    "    '''\n",
    "    Evaluate naive bayes classifier using 10-fold cross validation\n",
    "    Print out performance stats and confusion matrix for each fold\n",
    "    Print out average performance stats\n",
    "    \n",
    "    Parameters:\n",
    "        X (np.array): messages\n",
    "        y (np.array): labels (0 or 1) \n",
    "        laplace (bool): Whether or not to use laplace smoothing\n",
    "    '''\n",
    "    fold, total_conf = 0, [[0,0],[0,0]]\n",
    "    # Within train data, use 10-fold split, stratified based on spam label\n",
    "    trainKFold = StratifiedKFold(n_splits=10, shuffle=True, random_state=0)\n",
    "    for train_index, test_index in trainKFold.split(X, y):\n",
    "        fold += 1\n",
    "        X_train, X_val = X[train_index], X[test_index]\n",
    "        y_train, y_val = y[train_index], y[test_index]\n",
    "        \n",
    "        # Build model on train data\n",
    "        model = build_model(X_train, y_train, laplace)\n",
    "        # Predict based on validation data\n",
    "        y_pred = model_predict(model, X_val, laplace)\n",
    "        # Compare predicted labels with true labels\n",
    "        conf = confusion_matrix(y_val, y_pred)\n",
    "        total_conf += conf\n",
    "        \n",
    "        print(\"Fold {}:\".format(fold))\n",
    "        print_stats(conf)\n",
    "        print(\"  Confusion matrix:\\n{}\".format(conf))\n",
    "    \n",
    "    print(\"Average over all folds:\")\n",
    "    print_stats(total_conf/10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sized-mapping",
   "metadata": {},
   "source": [
    "### Naive Bayes training performance (ignoring words not in training data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "intensive-norway",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get 'message.csv' data\n",
    "msgdf = pd.read_csv(\"./message.csv\")\n",
    "X, y = msgdf['Message'].to_numpy(), msgdf['Label'].to_numpy()\n",
    "\n",
    "# Split data into train/test, stratified based on spam label\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=0, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "behavioral-review",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1:\n",
      "  Accuracy: 0.9641255605381166\n",
      "  Precision: 0.8833333333333333\n",
      "  Recal: 0.8548387096774194\n",
      "  Specificity: 0.9817708333333334\n",
      "  Confusion matrix:\n",
      "[[377   9]\n",
      " [  7  53]]\n",
      "Fold 2:\n",
      "  Accuracy: 0.968609865470852\n",
      "  Precision: 0.8833333333333333\n",
      "  Recal: 0.8833333333333333\n",
      "  Specificity: 0.9818652849740933\n",
      "  Confusion matrix:\n",
      "[[379   7]\n",
      " [  7  53]]\n",
      "Fold 3:\n",
      "  Accuracy: 0.9753363228699552\n",
      "  Precision: 0.9333333333333333\n",
      "  Recal: 0.8888888888888888\n",
      "  Specificity: 0.9895561357702349\n",
      "  Confusion matrix:\n",
      "[[379   7]\n",
      " [  4  56]]\n",
      "Fold 4:\n",
      "  Accuracy: 0.9641255605381166\n",
      "  Precision: 0.8166666666666667\n",
      "  Recal: 0.9074074074074074\n",
      "  Specificity: 0.9719387755102041\n",
      "  Confusion matrix:\n",
      "[[381   5]\n",
      " [ 11  49]]\n",
      "Fold 5:\n",
      "  Accuracy: 0.9775784753363229\n",
      "  Precision: 0.9666666666666667\n",
      "  Recal: 0.8787878787878788\n",
      "  Specificity: 0.9947368421052631\n",
      "  Confusion matrix:\n",
      "[[378   8]\n",
      " [  2  58]]\n",
      "Fold 6:\n",
      "  Accuracy: 0.9775784753363229\n",
      "  Precision: 0.95\n",
      "  Recal: 0.890625\n",
      "  Specificity: 0.9921465968586387\n",
      "  Confusion matrix:\n",
      "[[379   7]\n",
      " [  3  57]]\n",
      "Fold 7:\n",
      "  Accuracy: 0.9798206278026906\n",
      "  Precision: 0.9666666666666667\n",
      "  Recal: 0.8923076923076924\n",
      "  Specificity: 0.994750656167979\n",
      "  Confusion matrix:\n",
      "[[379   7]\n",
      " [  2  58]]\n",
      "Fold 8:\n",
      "  Accuracy: 0.9820224719101124\n",
      "  Precision: 0.9661016949152542\n",
      "  Recal: 0.9047619047619048\n",
      "  Specificity: 0.9947643979057592\n",
      "  Confusion matrix:\n",
      "[[380   6]\n",
      " [  2  57]]\n",
      "Fold 9:\n",
      "  Accuracy: 0.9573033707865168\n",
      "  Precision: 0.8813559322033898\n",
      "  Recal: 0.8125\n",
      "  Specificity: 0.9816272965879265\n",
      "  Confusion matrix:\n",
      "[[374  12]\n",
      " [  7  52]]\n",
      "Fold 10:\n",
      "  Accuracy: 0.9865168539325843\n",
      "  Precision: 0.9666666666666667\n",
      "  Recal: 0.9354838709677419\n",
      "  Specificity: 0.9947780678851175\n",
      "  Confusion matrix:\n",
      "[[381   4]\n",
      " [  2  58]]\n",
      "Average over all folds:\n",
      "  Accuracy: 0.9733004262957147\n",
      "  Precision: 0.9214046822742474\n",
      "  Recal: 0.884430176565008\n",
      "  Specificity: 0.9877412623891497\n"
     ]
    }
   ],
   "source": [
    "evaluate_naive_bayes(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pointed-monaco",
   "metadata": {},
   "source": [
    "**Summary:**\n",
    "\n",
    "This naive bayes classifier is quite good at identifying spam messages.\n",
    "The classifier works by treating a message $x$ as an input with $n$ features (where $n$ is the number of words in $x$). Then it performs maximum a posteriori (MAP) estimation to find the 0/1 label (0=='not spam', 1=='spam') that best represents the message. This is done by finding the $y\\in\\{0,1\\}$ label that maximizes the probability $P(y|x) \\propto P(y)\\Pi_{i=0}^{n}{P(x_i | y)}$. Although, since the product of the liklihood probabilities quickly approach zero, the code above uses log-liklihood: $\\log P(y|x) \\propto \\log P(y)\\Sigma_{i=0}^{n}{\\log P(x_i | y)}$. To calculate the prior $P(y=y')$, we can just determine the number of messages that are labeled $y'$ and divide by the total number of messages. To calculate the liklihood $P(x=x_i|y=y')$, we can use the equation $P(x=x_i|y=y')=\\frac{n_{x_i}}{n_{y'}}$. In this equation, $n_{x_i}$ is the number of times the word $x_i$ appears in messages labeled $y'$, and $n_{y'}$ is the total number of words in messages labeled $y'$. However, words with zero probability are completely ignored, as they have undefined log values.\n",
    "\n",
    "*Note*: Rather than keeping track of an entire $N\\times M$ matrix of unique words, as suggested in the hw instructions, I use 3 dictionaries. This may not save much space, but I found it makes the liklihood computation a little simpler once you get to the `model_predict()` function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "funky-clark",
   "metadata": {},
   "source": [
    "### Naive Bayes training performance (with laplace smoothing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "nominated-curtis",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1:\n",
      "  Accuracy: 0.9663677130044843\n",
      "  Precision: 0.9666666666666667\n",
      "  Recal: 0.8169014084507042\n",
      "  Specificity: 0.9946666666666667\n",
      "  Confusion matrix:\n",
      "[[373  13]\n",
      " [  2  58]]\n",
      "Fold 2:\n",
      "  Accuracy: 0.952914798206278\n",
      "  Precision: 0.9333333333333333\n",
      "  Recal: 0.7671232876712328\n",
      "  Specificity: 0.9892761394101877\n",
      "  Confusion matrix:\n",
      "[[369  17]\n",
      " [  4  56]]\n",
      "Fold 3:\n",
      "  Accuracy: 0.9798206278026906\n",
      "  Precision: 0.9833333333333333\n",
      "  Recal: 0.8805970149253731\n",
      "  Specificity: 0.9973614775725593\n",
      "  Confusion matrix:\n",
      "[[378   8]\n",
      " [  1  59]]\n",
      "Fold 4:\n",
      "  Accuracy: 0.9663677130044843\n",
      "  Precision: 0.95\n",
      "  Recal: 0.8260869565217391\n",
      "  Specificity: 0.9920424403183024\n",
      "  Confusion matrix:\n",
      "[[374  12]\n",
      " [  3  57]]\n",
      "Fold 5:\n",
      "  Accuracy: 0.9618834080717489\n",
      "  Precision: 0.9833333333333333\n",
      "  Recal: 0.7866666666666666\n",
      "  Specificity: 0.9973045822102425\n",
      "  Confusion matrix:\n",
      "[[370  16]\n",
      " [  1  59]]\n",
      "Fold 6:\n",
      "  Accuracy: 0.968609865470852\n",
      "  Precision: 0.9833333333333333\n",
      "  Recal: 0.8194444444444444\n",
      "  Specificity: 0.9973262032085561\n",
      "  Confusion matrix:\n",
      "[[373  13]\n",
      " [  1  59]]\n",
      "Fold 7:\n",
      "  Accuracy: 0.9663677130044843\n",
      "  Precision: 1.0\n",
      "  Recal: 0.8\n",
      "  Specificity: 1.0\n",
      "  Confusion matrix:\n",
      "[[371  15]\n",
      " [  0  60]]\n",
      "Fold 8:\n",
      "  Accuracy: 0.9617977528089887\n",
      "  Precision: 0.9830508474576272\n",
      "  Recal: 0.7837837837837838\n",
      "  Specificity: 0.9973045822102425\n",
      "  Confusion matrix:\n",
      "[[370  16]\n",
      " [  1  58]]\n",
      "Fold 9:\n",
      "  Accuracy: 0.9617977528089887\n",
      "  Precision: 0.9661016949152542\n",
      "  Recal: 0.7916666666666666\n",
      "  Specificity: 0.9946380697050938\n",
      "  Confusion matrix:\n",
      "[[371  15]\n",
      " [  2  57]]\n",
      "Fold 10:\n",
      "  Accuracy: 0.9573033707865168\n",
      "  Precision: 0.9833333333333333\n",
      "  Recal: 0.7662337662337663\n",
      "  Specificity: 0.9972826086956522\n",
      "  Confusion matrix:\n",
      "[[367  18]\n",
      " [  1  59]]\n",
      "Average over all folds:\n",
      "  Accuracy: 0.9643257796724253\n",
      "  Precision: 0.9732441471571907\n",
      "  Recal: 0.8027586206896552\n",
      "  Specificity: 0.9957127545551983\n"
     ]
    }
   ],
   "source": [
    "evaluate_naive_bayes(X_train, y_train, laplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "greatest-obligation",
   "metadata": {},
   "source": [
    "**Summary:**\n",
    "\n",
    "In this Naive Bayes classifier, we employ laplace smoothing.\n",
    "The classifier works similarly to the previous model, but the liklihood is calculated differently. Instead of ignoring words that did not appear in the training set, these words are given a small likihood (by assuming they appeared once in the training set). The new liklihood equation looks like $P(x=x_i|y=y')=\\frac{n_{x_i}+1}{n_{y'}+N}$. In this equation, $n_{x_i}$ is the number of times the word $x_i$ appears in messages labeled $y'$, $n_{y'}$ is the total number of words in messages labeled $y'$, and $N$ is the total number of features (ie words) appearing in the input message. This approach makes more sense from a theoretical standpoint, since \"ignoring\" words is actually treating them as having a liklihood of $1$. However, for this data set, it appears the laplace smoothing method results in a slightly less accurate classifier. Although, it has better precision and specificity, meaning that the spam classifications are more likely to be correct (than without smoothing)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "understood-crack",
   "metadata": {},
   "source": [
    "### Naive Bayes performance on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "southwest-result",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No laplace smoothing:\n",
      "  Accuracy: 0.9623318385650225\n",
      "  Precision: 0.9060402684563759\n",
      "  Recal: 0.8282208588957055\n",
      "  Specificity: 0.9852941176470589\n",
      "  Confusion matrix:\n",
      "[[938  28]\n",
      " [ 14 135]]\n",
      "With laplace smoothing:\n",
      "  Accuracy: 0.9614349775784753\n",
      "  Precision: 0.959731543624161\n",
      "  Recal: 0.7944444444444444\n",
      "  Specificity: 0.9935828877005347\n",
      "  Confusion matrix:\n",
      "[[929  37]\n",
      " [  6 143]]\n",
      "No laplace smoothing and ignoring stop words:\n",
      "  Accuracy: 0.9524663677130045\n",
      "  Precision: 0.912751677852349\n",
      "  Recal: 0.7727272727272727\n",
      "  Specificity: 0.9861554845580405\n",
      "  Confusion matrix:\n",
      "[[926  40]\n",
      " [ 13 136]]\n",
      "With laplace smoothing and ignoring stop words:\n",
      "  Accuracy: 0.95695067264574\n",
      "  Precision: 0.959731543624161\n",
      "  Recal: 0.772972972972973\n",
      "  Specificity: 0.9935483870967742\n",
      "  Confusion matrix:\n",
      "[[924  42]\n",
      " [  6 143]]\n"
     ]
    }
   ],
   "source": [
    "# Train models on all training data, test on remaining 20%\n",
    "\n",
    "# No laplace smoothing. Keep stop words\n",
    "model = build_model(X_train, y_train)\n",
    "y_pred = model_predict(model, X_test)\n",
    "conf = confusion_matrix(y_test, y_pred)\n",
    "print(\"No laplace smoothing:\")\n",
    "print_stats(conf)\n",
    "print(\"  Confusion matrix:\\n{}\".format(conf))\n",
    "\n",
    "# With laplace smoothing. Keep stop words\n",
    "model = build_model(X_train, y_train, laplace=True)\n",
    "y_pred = model_predict(model, X_test, laplace=True)\n",
    "conf = confusion_matrix(y_test, y_pred)\n",
    "print(\"With laplace smoothing:\")\n",
    "print_stats(conf)\n",
    "print(\"  Confusion matrix:\\n{}\".format(conf))\n",
    "\n",
    "# No laplace smoothing. Remove stop words\n",
    "model = build_model(X_train, y_train, laplace=False, ignore_stop_words=True)\n",
    "y_pred = model_predict(model, X_test, laplace=False, ignore_stop_words=True)\n",
    "conf = confusion_matrix(y_test, y_pred)\n",
    "print(\"No laplace smoothing and ignoring stop words:\")\n",
    "print_stats(conf)\n",
    "print(\"  Confusion matrix:\\n{}\".format(conf))\n",
    "\n",
    "# With laplace smoothing. Remove stop words\n",
    "model = build_model(X_train, y_train, laplace=True, ignore_stop_words=True)\n",
    "y_pred = model_predict(model, X_test, laplace=True, ignore_stop_words=True)\n",
    "conf = confusion_matrix(y_test, y_pred)\n",
    "print(\"With laplace smoothing and ignoring stop words:\")\n",
    "print_stats(conf)\n",
    "print(\"  Confusion matrix:\\n{}\".format(conf))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sustained-marriage",
   "metadata": {},
   "source": [
    "**Summary**:\n",
    "\n",
    "We originally created an 80-20 stratified test-train split in our data. The code above shows the results of training the model on the full 80% of data, then testing on the remaining 20%. We can see that again the laplace smoothing gives us much better precision and specificity, at a small cost to the recall and accuracy. For this data set, it seems that implementing laplace smoothing makes the model less sensitive to messages that may be \"spam\" messages... but this may be helpful if we don't want our model to create too many false positives.\n",
    "\n",
    "We also test here two models that ignore \"stop words\". These stop words are a corpus of words that appear frequently in the english dictionary. They are also words that do not carry much meaning, such as \"in\", \"an\", \"the\", \"about\", etc.\n",
    "Since stop words do not have much semantic influence on a sentence, they also should not influence whether or not a message is \"spam\". However, we can see that the models that ignore stop words actually perform slightly worse. Again, this probably has to do with our particular data set. It seems that the normal model is able to find some correlation between stop words and spam messages; hence removing stop words hurts our classifier's performance. It might be interesting to try to see which stop words had the highest liklihoods within spam/not-spam messages. There may be a couple stop words in the corpus that actually carry some semantic weight in regards to this classifcation process."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "soviet-forward",
   "metadata": {},
   "source": [
    "## Resources used in Question 1\n",
    "* Pandas documentation for references on DataFrames (https://pandas.pydata.org/docs/)\n",
    "* Scikit Learn documentation and sample code for [train_test_split](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html), [StratifiedKFold](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.StratifiedKFold.html), and [confusion_matrix](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html)\n",
    "* Referenced Wikipedia definitions of precision, recall, and specificity: https://en.wikipedia.org/wiki/Precision_and_recall, https://en.wikipedia.org/wiki/Sensitivity_and_specificity\n",
    "* GeeksForGeeks tutorial on removing stop words: https://www.geeksforgeeks.org/removing-stop-words-nltk-python/\n",
    "* Referenced my (Andrew Corum's) previously completed B551 assignment where I created a Naive Bayes classifier (from Fall 2020). I did not copy any of my old code, but I did use it as a reference. Some of my structure is similar. For example, in the B551 assignment I had the idea to save the model as three dictionaries (`prior`, `label_word_count`, and `word_count`). But again, I only used this as a reference, and it was all code that was written by me."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "allied-version",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "funded-enlargement",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
